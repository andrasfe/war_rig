# War Rig Configuration
# OpenRouter API Settings

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# LLM Provider Configuration
LLM_PROVIDER=openrouter

# OpenRouter Settings (when LLM_PROVIDER=openrouter)
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# =============================================================================
# API PROVIDER
# =============================================================================
API_PROVIDER=openrouter

# Optional: For OpenRouter rankings/routing
OPENROUTER_SITE_URL=https://github.com/your-org/war-rig
OPENROUTER_SITE_NAME=War Rig Mainframe Docs

# =============================================================================
# MODEL ASSIGNMENTS
# =============================================================================

# Scribe (Documenter) - Needs strong code comprehension and detail orientation
# Good at: filling templates, extracting information, following instructions
SCRIBE_MODEL=anthropic/claude-sonnet-4-20250514
SCRIBE_TEMPERATURE=0.3
SCRIBE_MAX_TOKENS=4000

# Challenger (Validator) - Needs critical thinking, questioning ability
# Good at: finding gaps, asking probing questions, verification
# Using a different provider for diversity of perspective
CHALLENGER_MODEL=openai/gpt-4o-2024-11-20
CHALLENGER_TEMPERATURE=0.5
CHALLENGER_MAX_TOKENS=2000

# Imperator (Reviewer) - Needs judgment, decision making
# Good at: evaluation, synthesis, final decisions
IMPERATOR_MODEL=anthropic/claude-sonnet-4-20250514
IMPERATOR_TEMPERATURE=0.2
IMPERATOR_MAX_TOKENS=2000

# Super-Scribe (Automatic rescue for blocked tickets)
# When tickets fail on all normal workers, Super-Scribe automatically retries
# with a stronger model. Uses Opus by default for maximum capability.
SUPER_SCRIBE_MODEL=anthropic/claude-opus-4-20250514
NUM_SUPER_SCRIBES=1

# =============================================================================
# ATLAS CHUNKING SETTINGS (for large files exceeding context)
# =============================================================================

# Enable Atlas for large file chunking (default: true)
ATLAS_ENABLED=true

# Token budget - files larger than this get chunked (default: 4000)
ATLAS_CONTEXT_BUDGET=4000

# Maximum tokens per chunk - should be < context budget (default: 3500)
ATLAS_MAX_CHUNK_TOKENS=3500

# Maximum inputs per merge node in DAG (default: 15)
ATLAS_MAX_MERGE_FAN_IN=15

# Maximum challenger iterations for chunked processing (default: 3)
ATLAS_MAX_CHALLENGE_ITERATIONS=3

# Use COBOL-aware semantic boundaries vs line-based (default: true)
ATLAS_SEMANTIC_CHUNKING=true

# =============================================================================
# ALTERNATIVE MODEL OPTIONS (comment/uncomment as needed)
# =============================================================================

# Budget-friendly alternatives:
# SCRIBE_MODEL=meta-llama/llama-3.3-70b-instruct
# CHALLENGER_MODEL=google/gemini-2.0-flash-001
# IMPERATOR_MODEL=meta-llama/llama-3.3-70b-instruct

# Premium alternatives:
# SCRIBE_MODEL=anthropic/claude-opus-4-20250514
# CHALLENGER_MODEL=openai/gpt-4o
# IMPERATOR_MODEL=anthropic/claude-opus-4-20250514

# All same model (for testing):
# SCRIBE_MODEL=anthropic/claude-sonnet-4-20250514
# CHALLENGER_MODEL=anthropic/claude-sonnet-4-20250514
# IMPERATOR_MODEL=anthropic/claude-sonnet-4-20250514

# =============================================================================
# WORKFLOW SETTINGS
# =============================================================================

# Number of redundant teams processing in parallel (default=1)
# Higher values increase reliability but also cost
NUM_TEAMS=1

# Maximum iterations before forced approval
MAX_ITERATIONS=3

# Maximum questions Challenger can ask per round
MAX_QUESTIONS_PER_ROUND=5

# Maximum Chrome tickets Imperator can issue per round
MAX_CHROME_TICKETS=5

# Number of parallel Scribe workers (1-10)
NUM_SCRIBES=3

# Number of parallel Challenger workers (1-10)
NUM_CHALLENGERS=2

# Max Program Manager cycles before forced completion (1-20)
PM_MAX_CYCLES=5

# =============================================================================
# INPUT/OUTPUT PATHS
# =============================================================================

# CardDemo test repository (clone separately)
INPUT_DIRECTORY=./aws-mainframe-modernization-carddemo/app
OUTPUT_DIRECTORY=./output

# =============================================================================
# PREPROCESSING
# =============================================================================

# What to extract during preprocessing
EXTRACT_PARAGRAPHS=true
EXTRACT_PERFORMS=true
EXTRACT_CALLS=true
EXTRACT_COPYBOOKS=true
EXTRACT_SQL=true
EXTRACT_CICS=true

# =============================================================================
# LOGGING
# =============================================================================

LOG_LEVEL=INFO
LOG_FILE=./output/war_rig.log
SAVE_DIALOGUES=true

# =============================================================================
# CHECKPOINTING
# =============================================================================

CHECKPOINT_ENABLED=true
CHECKPOINT_FREQUENCY=per_program
CHECKPOINT_DIRECTORY=./output/checkpoints

# =============================================================================
# BEADS INTEGRATION
# =============================================================================

# Enable beads ticket creation for agent issues
BEADS_ENABLED=true

# Dry run mode - log ticket operations without creating them
BEADS_DRY_RUN=false